generation:
  num_subsamples: 3
  num_demos: 5
  num_prompts_per_subsample: 30
  model:
    name: GPT_forward
    batch_size: 3
    gpt_config:
      # model: meta-llama/Meta-Llama-3-8B-Instruct
      model: meta-llama/Llama-3.3-70B-Instruct
      #model: google/flan-t5-base
      temperature: 0.9
      max_tokens: 50
      top_p: 0.9
      frequency_penalty: 1.0
evaluation:
  method: exec_accuracy
  num_samples: 30
  num_few_shot: 5
  model:
    name: GPT_forward
    batch_size: 1000
    gpt_config:
      model: meta-llama/Meta-Llama-3-8B-Instruct
      temperature: 0.7
      max_tokens: 200
      top_p: 1.0
      frequency_penalty: 1.0
demo:
  model:
    name: GPT_forward
    batch_size: 500
    gpt_config:
      model: meta-llama/Meta-Llama-3-8B-Instruct
      temperature: 0.7
      max_tokens: 200
      top_p: 1.0
      frequency_penalty: 1.0
